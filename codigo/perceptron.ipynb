{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c267ed06",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o e Estrutura B√°sica do Perceptron\n",
    "\n",
    "O Perceptron foi o primeiro neur√¥nio artificial criado, sendo o precursor das redes neurais artificiais. Foi desenvolvido por Frank Rosenblatt, em 1958.  \n",
    "A proposta do Perceptron era atuar com o reconhecimento de padr√µes, empregando o uso de pesos e de outras caracter√≠sticas que foram inseridas nas redes neurais atuais.  \n",
    "\n",
    "A solu√ß√£o de Rosenblatt apresentava apenas uma camada e classificava os valores de entrada entre os pertencentes a uma das duas classes cadastradas.  \n",
    "O Perceptron pode ser entendido como um modelo simples de neur√¥nio artificial que realiza decis√µes baseadas em m√∫ltiplas entradas.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura B√°sica do Perceptron \n",
    "\n",
    "Entradas (xi): Os valores num√©ricos de entrada correspondem √†s caracter√≠sticas, s√£o os valores que alimentam o neur√¥nio. \n",
    "Pesos (wi): Cada caracter√≠stica tem um peso atribu√≠do; isso determina sua import√¢ncia. \n",
    "Sa√≠da (y): √â calculada usando entradas e pesos. A sa√≠da √© bin√°ria (1,0) ou um valor em um intervalo cont√≠nuo.\n",
    "Bias (b): Valor constante adicionado ao somat√≥rio para ajustar o resultado.\n",
    "Somat√≥rio: Combina a entrada(xi) e os pesos(wi):\n",
    "<p align=\"center\">\n",
    "<img src=\"imagens/somatorio.png\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\"><em>Figura 1: F√≥rmula do somat√≥rio.</em></p>\n",
    "Fun√ß√£o de ativa√ß√£o: Transforma o resultado ùë¢ em uma sa√≠da bin√°ria (0 ou 1) com a fun√ß√£o degrau unit√°rio:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imagens/funcao_atv.png\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\"><em>Figura 2: Fun√ß√£o degrau unit√°rio.</em></p>\n",
    "\n",
    "Suponha que temos tr√™s entradas: `x‚ÇÅ`, `x‚ÇÇ` e `x‚ÇÉ`. Cada entrada √© multiplicada por um peso associado: `w‚ÇÅ`, `w‚ÇÇ` e `w‚ÇÉ`. Os pesos determinam a import√¢ncia de cada entrada no processo de decis√£o.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imagens/estrutura.png\" width=\"400\">\n",
    "</p>\n",
    "<p align=\"center\"><em>Figura 3: Estrutura do perceptron.</em></p>\n",
    "\n",
    "Al√©m dessas entradas, o Perceptron tamb√©m inclui uma entrada extra chamada bias, que tem valor fixo (geralmente 1) e tamb√©m possui um peso associado `w_b`. O bias funciona como um ajuste fino, permitindo que o modelo tenha mais flexibilidade para aprender padr√µes nos dados.\n",
    "O resultado desta soma ponderada, representada por `s`, alimenta uma un√ß√£o de ativa√ß√£o que transforma esse valor em uma sa√≠da final, `y`.\n",
    "\n",
    "No Perceptron cl√°ssico, essa fun√ß√£o de ativa√ß√£o √© uma fun√ß√£o degrau, que funciona da seguinte forma:\n",
    "\n",
    "- Se `s ‚â• 0`: o neur√¥nio √© ativado ‚Üí `y = 1`\n",
    "- Se `s < 0`: o neur√¥nio permanece desativado ‚Üí `y = 0`\n",
    "\n",
    "## Implementa√ß√£o do Perceptron\n",
    "\n",
    "C√≥digo manual implementa a opera√ß√£o b√°sica do Perceptron, onde:  \n",
    "‚Ä¢ u √© o valor intermedi√°rio antes da ativa√ß√£o.  \n",
    "‚Ä¢ wi s√£o os pesos.  \n",
    "‚Ä¢ xi s√£o as entradas.  \n",
    "‚Ä¢ b √© o bias (vi√©s).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153557cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de u (pr√©-ativa√ß√£o): 0.5\n",
      "Sa√≠da do perceptron (y): 1\n"
     ]
    }
   ],
   "source": [
    "# C√≥digo que implementa a opera√ß√£o b√°sica do Perceptron:\n",
    "x = [0.0, 0.0, 0.0]\n",
    "w = [1.0, 1.0, 1.0]\n",
    "b = 0.5                \n",
    "u = 0  # Inicializando \n",
    "\n",
    "for i in range(len(x)):\n",
    "    produto = x[i] * w[i]\n",
    "    u += produto\n",
    "\n",
    "# Soma do bias\n",
    "u += b\n",
    "\n",
    "# Fun√ß√£o de ativa√ß√£o (fun√ß√£o degrau)\n",
    "if u >= 0:\n",
    "    y = 1\n",
    "else:\n",
    "    y = 0\n",
    "\n",
    "print(\"Valor de u (pr√©-ativa√ß√£o):\", u)\n",
    "print(\"Sa√≠da do perceptron (y):\", y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3adee",
   "metadata": {},
   "source": [
    "## 2. Explica√ß√£o do c√°lculo Matem√°tico do Perceptron\n",
    "\n",
    "O c√≥digo acima implementa a opera√ß√£o b√°sica do Perceptron realiza a **soma ponderada das entradas** com seus respectivos pesos, e realiza a soma desse valor com o bias. A f√≥rmula geral para o c√°lculo da entrada l√≠quida (u) √©:\n",
    "\n",
    "\\[\n",
    "u = x_1 w_1 + x_2 w_2 + \\cdots + x_n w_n + b\n",
    "\\]\n",
    "\n",
    "Ou, em nota√ß√£o de somat√≥rio, como mostrado na imagem 1.\n",
    "\n",
    "No exemplo realizado, foram adicionados valores para entradas, pesos e bias.\n",
    "\n",
    "- Entradas:  x = [0.0, 0.0, 0.0] \n",
    "- Pesos: w = [1.0, 1.0, 1.0] \n",
    "- Bias: b = 0.5 \n",
    "\n",
    "A multiplica√ß√£o dos valores ocorre elemento a elemento,temos ent√£o:\n",
    "\n",
    "x‚ÇÅ ‚ãÖ w‚ÇÅ = 0.0 ‚ãÖ 1.0 = 0.0  \n",
    "x‚ÇÇ ‚ãÖ w‚ÇÇ = 0.0 ‚ãÖ 1.0 = 0.0  \n",
    "x‚ÇÉ ‚ãÖ w‚ÇÉ = 0.0 ‚ãÖ 1.0 = 0.0\n",
    "\n",
    "u = 0.0 + 0.0 + 0.0 + 0.5 = 0.5\n",
    "\n",
    "Esse valor \\( u \\) √© ent√£o passado para a **fun√ß√£o de ativa√ß√£o**, que decide a sa√≠da do neur√¥nio (0 ou 1).\n",
    "No exemplo, a fun√ß√£o utilizada foi a fun√ß√£o degrau unit√°rio, se o valor de ùë¢ for maior ou igual a zero, a sa√≠da ser√° 1, caso contr√°rio, a sa√≠da ser√° 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
