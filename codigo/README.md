## Introdu√ß√£o e Estrutura B√°sica do Perceptron

O Perceptron foi o primeiro neur√¥nio artificial criado, sendo o precursor das redes neurais artificiais. Foi desenvolvido por Frank Rosenblatt, em 1958.  
A proposta do Perceptron era atuar com o reconhecimento de padr√µes, empregando o uso de pesos e de outras caracter√≠sticas que foram inseridas nas redes neurais atuais.  

A solu√ß√£o de Rosenblatt apresentava apenas uma camada e classificava os valores de entrada entre os pertencentes a uma das duas classes cadastradas.  
O Perceptron pode ser entendido como um modelo simples de neur√¥nio artificial que realiza decis√µes baseadas em m√∫ltiplas entradas.

---

## Estrutura B√°sica do Perceptron 

Entradas (xi): Os valores num√©ricos de entrada correspondem √†s caracter√≠sticas, s√£o os valores que alimentam o neur√¥nio. 
Pesos (wi): Cada caracter√≠stica tem um peso atribu√≠do; isso determina sua import√¢ncia. 
Sa√≠da (y): √â calculada usando entradas e pesos. A sa√≠da √© bin√°ria (1,0) ou um valor em um intervalo cont√≠nuo.
Bias (b): Valor constante adicionado ao somat√≥rio para ajustar o resultado.
Somat√≥rio: Combina a entrada(xi) e os pesos(wi):
<p align="center">
<img src="imagens/somatorio.png" width="400">
</p>
<p align="center"><em>Figura 1: F√≥rmula do somat√≥rio.</em></p>
Fun√ß√£o de ativa√ß√£o: Transforma o resultado ùë¢ em uma sa√≠da bin√°ria (0 ou 1) com a fun√ß√£o degrau unit√°rio:

<p align="center">
<img src="imagens/funcao_atv.png" width="400">
</p>
<p align="center"><em>Figura 2: Fun√ß√£o degrau unit√°rio.</em></p>

Suponha que temos tr√™s entradas: `x‚ÇÅ`, `x‚ÇÇ` e `x‚ÇÉ`. Cada entrada √© multiplicada por um peso associado: `w‚ÇÅ`, `w‚ÇÇ` e `w‚ÇÉ`. Os pesos determinam a import√¢ncia de cada entrada no processo de decis√£o.

<p align="center">
<img src="imagens/estrutura.png" width="400">
</p>
<p align="center"><em>Figura 3: Estrutura do perceptron.</em></p>

Al√©m dessas entradas, o Perceptron tamb√©m inclui uma entrada extra chamada bias, que tem valor fixo (geralmente 1) e tamb√©m possui um peso associado `w_b`. O bias funciona como um ajuste fino, permitindo que o modelo tenha mais flexibilidade para aprender padr√µes nos dados.
O resultado desta soma ponderada, representada por `s`, alimenta uma un√ß√£o de ativa√ß√£o que transforma esse valor em uma sa√≠da final, `y`.

No Perceptron cl√°ssico, essa fun√ß√£o de ativa√ß√£o √© uma fun√ß√£o degrau, que funciona da seguinte forma:

- Se `s ‚â• 0`: o neur√¥nio √© ativado ‚Üí `y = 1`
- Se `s < 0`: o neur√¥nio permanece desativado ‚Üí `y = 0`

## Implementa√ß√£o do Perceptron

C√≥digo manual implementa a opera√ß√£o b√°sica do Perceptron, onde:  
‚Ä¢ u √© o valor intermedi√°rio antes da ativa√ß√£o.  
‚Ä¢ wi s√£o os pesos.  
‚Ä¢ xi s√£o as entradas.  
‚Ä¢ b √© o bias (vi√©s).


implementa√ß√£o: implementa√ß√£o: [perceptron.ipynb](perceptron.ipynb)

## 2. Explica√ß√£o do c√°lculo Matem√°tico do Perceptron

O c√≥digo acima implementa a opera√ß√£o b√°sica do Perceptron realiza a **soma ponderada das entradas** com seus respectivos pesos, e realiza a soma desse valor com o bias. A f√≥rmula geral para o c√°lculo da entrada l√≠quida (u) √©:

\[
u = x_1 w_1 + x_2 w_2 + \cdots + x_n w_n + b
\]

Ou, em nota√ß√£o de somat√≥rio, como mostrado na imagem 1.

No exemplo realizado, foram adicionados valores para entradas, pesos e bias.

- Entradas:  x = [0.0, 0.0, 0.0] 
- Pesos: w = [1.0, 1.0, 1.0] 
- Bias: b = 0.5 

A multiplica√ß√£o dos valores ocorre elemento a elemento,temos ent√£o:

x‚ÇÅ ‚ãÖ w‚ÇÅ = 0.0 ‚ãÖ 1.0 = 0.0  
x‚ÇÇ ‚ãÖ w‚ÇÇ = 0.0 ‚ãÖ 1.0 = 0.0  
x‚ÇÉ ‚ãÖ w‚ÇÉ = 0.0 ‚ãÖ 1.0 = 0.0

u = 0.0 + 0.0 + 0.0 + 0.5 = 0.5

Esse valor \( u \) √© ent√£o passado para a **fun√ß√£o de ativa√ß√£o**, que decide a sa√≠da do neur√¥nio (0 ou 1).
No exemplo, a fun√ß√£o utilizada foi a fun√ß√£o degrau unit√°rio, se o valor de ùë¢ for maior ou igual a zero, a sa√≠da ser√° 1, caso contr√°rio, a sa√≠da ser√° 0.
