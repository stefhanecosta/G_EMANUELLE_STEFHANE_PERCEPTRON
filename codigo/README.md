## Introdu√ß√£o e Estrutura B√°sica do Perceptron

O Perceptron foi o primeiro neur√¥nio artificial criado, sendo o precursor das redes neurais artificiais. Foi desenvolvido por Frank Rosenblatt, em 1958.  
A proposta do Perceptron era atuar com o reconhecimento de padr√µes, empregando o uso de pesos e de outras caracter√≠sticas que foram inseridas nas redes neurais atuais.  

A solu√ß√£o de Rosenblatt apresentava apenas uma camada e classificava os valores de entrada entre os pertencentes a uma das duas classes cadastradas.  
O Perceptron pode ser entendido como um modelo simples de neur√¥nio artificial que realiza decis√µes baseadas em m√∫ltiplas entradas.

---

## Estrutura B√°sica do Perceptron 

Entradas (xi): Os valores num√©ricos de entrada correspondem √†s caracter√≠sticas, s√£o os valores que alimentam o neur√¥nio. 
Pesos (wi): Cada caracter√≠stica tem um peso atribu√≠do; isso determina sua import√¢ncia. 
Sa√≠da (y): √â calculada usando entradas e pesos. A sa√≠da √© bin√°ria (1,0) ou um valor em um intervalo cont√≠nuo.
Bias (b): Valor constante adicionado ao somat√≥rio para ajustar o resultado.
Somat√≥rio: Combina a entrada(xi) e os pesos(wi):
<p align="center">
<img src="imagens/somatorio.png" width="400">
</p>
Fun√ß√£o de ativa√ß√£o: Transforma o resultado ùë¢ em uma sa√≠da bin√°ria (0 ou 1) com a fun√ß√£o degrau unit√°rio:

<p align="center">
<img src="imagens/funcao_atv.png" width="400">
</p>

Suponha que temos tr√™s entradas: `x‚ÇÅ`, `x‚ÇÇ` e `x‚ÇÉ`. Cada entrada √© multiplicada por um peso associado: `w‚ÇÅ`, `w‚ÇÇ` e `w‚ÇÉ`. Os pesos determinam a import√¢ncia de cada entrada no processo de decis√£o.

<p align="center">
<img src="imagens/estrutura.png" width="400">
</p>

Al√©m dessas entradas, o Perceptron tamb√©m inclui uma entrada extra chamada bias, que tem valor fixo (geralmente 1) e tamb√©m possui um peso associado `w_b`. O bias funciona como um ajuste fino, permitindo que o modelo tenha mais flexibilidade para aprender padr√µes nos dados.
O resultado desta soma ponderada, representada por `s`, alimenta uma un√ß√£o de ativa√ß√£o que transforma esse valor em uma sa√≠da final, `y`.

No Perceptron cl√°ssico, essa fun√ß√£o de ativa√ß√£o √© uma fun√ß√£o degrau, que funciona da seguinte forma:

- Se `s ‚â• 0`: o neur√¥nio √© ativado ‚Üí `y = 1`
- Se `s < 0`: o neur√¥nio permanece desativado ‚Üí `y = 0`

## Implementa√ß√£o do Perceptron

C√≥digo manual implementa a opera√ß√£o b√°sica do Perceptron, onde:  
‚Ä¢ u √© o valor intermedi√°rio antes da ativa√ß√£o.  
‚Ä¢ wi s√£o os pesos.  
‚Ä¢ xi s√£o as entradas.  
‚Ä¢ b √© o bias (vi√©s).


implementa√ß√£o: implementa√ß√£o: [perceptron.ipynb](perceptron.ipynb)
